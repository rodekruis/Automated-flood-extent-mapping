{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import ttach as tta\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path.cwd() / 'sentinel_one_test_data' / 'tiles'\n",
    "\n",
    "df_paths = pd.DataFrame({\n",
    "    'vv_image_path': list(data_folder.glob('vv/*')),\n",
    "    'vh_image_path': list(data_folder.glob('vh/*')),\n",
    "    'flood_label_path': list(data_folder.glob('flood_label/*'))\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s1_to_rgb(vv_image, vh_image):\n",
    "    ratio_image = np.clip(np.nan_to_num(vh_image/vv_image, 0), 0, 1)\n",
    "    rgb_image = np.stack((vv_image, vh_image, 1-ratio_image), axis=2)\n",
    "    return rgb_image\n",
    "\n",
    "class ETCIDataset(Dataset):\n",
    "    def __init__(self, dataframe, split, transform=None):\n",
    "        self.split = split\n",
    "        self.dataset = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = {}\n",
    "        \n",
    "        df_row = self.dataset.iloc[index]\n",
    "\n",
    "        print(df_row['vv_image_path'])\n",
    "\n",
    "        # load vv and vh images\n",
    "        vv_image = cv2.imread(str(df_row['vv_image_path']), 0) / 255.0\n",
    "        vh_image = cv2.imread(str(df_row['vh_image_path']), 0) / 255.0\n",
    "        \n",
    "        # convert vv and ch images to rgb\n",
    "        rgb_image = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "        if self.split == 'test':\n",
    "            # no flood mask should be available\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')\n",
    "        else:\n",
    "            # load ground truth flood mask\n",
    "            flood_mask = cv2.imread(df_row['flood_label_path'], 0) / 255.0\n",
    "\n",
    "            # compute transformations\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=rgb_image, mask=flood_mask)\n",
    "                rgb_image = augmented['image']\n",
    "                flood_mask = augmented['mask']\n",
    "\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')\n",
    "            example['mask'] = flood_mask.astype('int64')\n",
    "\n",
    "        return example\n",
    "    \n",
    "etci_dataset = ETCIDataset(df_paths, split='test', transform=None)\n",
    "\n",
    "# Original NVIDIA settings\n",
    "# batch_size = 96 * torch.cuda.device_count()\n",
    "# num_workers=os.cpu_count(),\n",
    "batch_size = 1\n",
    "num_workers=0\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    etci_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_single(model_def, weights):\n",
    "#   model_def.load_state_dict(torch.load(weights))\n",
    "    model_def.load_state_dict(torch.load(weights, map_location=torch.device('cpu')))\n",
    "    model = tta.SegmentationTTAWrapper(model_def, tta.aliases.d4_transform(), merge_mode='mean') # mean yields the best results\n",
    "    model.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    final_predictions = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            # load image and mask into device memory\n",
    "            image = batch['image'].to(device)\n",
    "\n",
    "            # pass images into model\n",
    "            pred = model(image)\n",
    "\n",
    "            # add to final predictions\n",
    "            final_predictions.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    final_predictions = np.concatenate(final_predictions, axis=0)\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_mobilenet = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\", \n",
    "    encoder_weights=None, \n",
    "    in_channels=3,                  \n",
    "    classes=2                      \n",
    ")\n",
    "\n",
    "upp_mobilenet = smp.UnetPlusPlus(\n",
    "    encoder_name=\"mobilenet_v2\", \n",
    "    encoder_weights=None, \n",
    "    in_channels=3,                  \n",
    "    classes=2                      \n",
    ")\n",
    "\n",
    "unet_pseudo_round2 = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\", \n",
    "    encoder_weights=None, \n",
    "    in_channels=3,                  \n",
    "    classes=2                      \n",
    ")\n",
    "\n",
    "model_defs = [unet_mobilenet, upp_mobilenet, unet_pseudo_round2]\n",
    "\n",
    "model_paths = [\n",
    "    Path.cwd() / 'models' / 'unet_mobilenet_v2_0.pth',\n",
    "    Path.cwd() / 'models' / 'upp_mobilenetv2_0.pth',\n",
    "    Path.cwd() / 'models' / 'unet_pseudo_mobilenetv2_round2_0.pth'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "for defi, path in zip(model_defs, model_paths):\n",
    "    all_preds.append(get_predictions_single(defi, path))\n",
    "    \n",
    "all_preds = np.array(all_preds)\n",
    "all_preds = np.mean(all_preds, axis=0)\n",
    "class_preds = all_preds.argmax(axis=1).astype('uint8')\n",
    "\n",
    "save_path = Path.cwd() / 'sentinel_one_test_data' / 'output' / 'submission.npy'\n",
    "np.save(save_path, class_preds, fix_imports=True, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 4\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(15, 15))\n",
    "\n",
    "ax1.set_title('vh')\n",
    "ax1.imshow(cv2.imread(str(df_paths['vh_image_path'][image_num]), 0) / 255.0)\n",
    "\n",
    "ax2.set_title('vv')\n",
    "ax2.imshow(cv2.imread(str(df_paths['vv_image_path'][image_num]), 0) / 255.0)\n",
    "\n",
    "flood_labels = cv2.imread(str(df_paths['flood_label_path'][image_num]), 0) / 255\n",
    "ax3.set_title('label')\n",
    "ax3.imshow(flood_labels)\n",
    "\n",
    "flood_preds = class_preds[image_num]\n",
    "ax4.set_title('Pred')\n",
    "ax4.imshow(flood_preds)\n",
    "\n",
    "intersection = np.logical_and(flood_labels, flood_preds)\n",
    "union = np.logical_or(flood_labels, flood_preds)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(f\"IOU score: {iou_score:.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_labels = cv2.imread(str(df_paths['flood_label_path'][image_num]), 0) / 255\n",
    "flood_preds = class_preds[image_num]\n",
    "\n",
    "intersection = np.logical_and(flood_labels, flood_preds)\n",
    "union = np.logical_or(flood_labels, flood_preds)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "iou_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated-flood-extent-mapping-iiypELG_-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
