# NVIDIA Sentinel one forecaster
An example notebook has been created for using the inference of the NVIDIA flood detection model. It was based off of this repository: https://github.com/sidgan/ETCI-2021-Competition-on-Flood-Detection . The requirements there are outdated and missing packages, the data of the competition is unavailable and the scripts aren't all that clear. What was still available though was their pre-trained models. The training data of the competition was still available through this dubious link: [https://drive.google.com/uc?id=14HqNW5uWLS92n7KrxKgDwUTsSEST6LCr](https://drive.google.com/uc?id=14HqNW5uWLS92n7KrxKgDwUTsSEST6LCr)

To reproducibly test the functionality a simple notebook has been created in `notebooks/run_nvidia_sentinel_one.ipynb`. The required packages are added to our poetry. A subset of the data from the google drive link above was added to `/sentinel_one_test_data`. The pre-trained models can be downloaded [here](https://github.com/sidgan/ETCI-2021-Competition-on-Flood-Detection/releases/download/v1.0.0/pretrained_weights.tar.gz) and should be placed in the `/models` folder.

With that everything should be in place to run the example notebook. It is set up to run on CPU, which is fine up to a couple of thousand images. If you do it on the complete competition training set it takes a while. It produces an output file in `sentinel_one_test_data/output`. Furthermore, at the bottom of the notebook you can check out the classification image next to its input images and actual label. It's not doing great I'd say but it does usually detect whether or not there is a flood present at all. Unfortunately we cannot verify it is running up to quality as the validation and test set of the competition don't seem to be available anywhere.
